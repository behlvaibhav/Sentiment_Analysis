{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     @user when a father is dysfunctional and is s...\n",
       "1    @user @user thanks for #lyft credit i can't us...\n",
       "2                                  bihday your majesty\n",
       "3    #model   i love u take with u all the time in ...\n",
       "4               factsguide: society now    #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['tweet']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['label']\n",
    "Y.head()\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ', lower=True, char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "# add padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   95, 8136,  480],\n",
       "       [   0,    0,    0, ..., 8137,    8, 8138],\n",
       "       [   0,    0,    0, ...,   62,   26, 3422],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   78,   11,  121],\n",
       "       [   0,    0,    0, ..., 1650, 1651,  679],\n",
       "       [   0,    0,    0, ...,    9,    6,  181]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @user lmfao pathetic #soit   #growup #funny #noonethere #iknowwhoitis ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82â\\x80¦'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['tweet'], key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel(\"No. of components\")\n",
    "plt.ylabel(\"cummulative explained Variance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu' ,input_dim =X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dense(2,kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_e = OneHotEncoder()\n",
    "Y_train_org = Y_train\n",
    "Y_test_org = Y_test\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "y_e.fit(Y_train)\n",
    "Y_train = y_e.transform(Y_train)\n",
    "Y_test = y_e.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25569x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25569 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6393x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6393 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25569 samples, validate on 6393 samples\n",
      "Epoch 1/100\n",
      "25569/25569 [==============================] - 2s 82us/step - loss: 0.2811 - acc: 0.9296 - val_loss: 0.2488 - val_acc: 0.9287\n",
      "Epoch 2/100\n",
      "25569/25569 [==============================] - 1s 56us/step - loss: 0.2436 - acc: 0.9301 - val_loss: 0.2473 - val_acc: 0.9287\n",
      "Epoch 3/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2422 - acc: 0.9301 - val_loss: 0.2488 - val_acc: 0.9287\n",
      "Epoch 4/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2417 - acc: 0.9301 - val_loss: 0.2501 - val_acc: 0.9287\n",
      "Epoch 5/100\n",
      "25569/25569 [==============================] - 2s 59us/step - loss: 0.2409 - acc: 0.9301 - val_loss: 0.2477 - val_acc: 0.9287\n",
      "Epoch 6/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2406 - acc: 0.9301 - val_loss: 0.2470 - val_acc: 0.9287\n",
      "Epoch 7/100\n",
      "25569/25569 [==============================] - 1s 59us/step - loss: 0.2401 - acc: 0.9301 - val_loss: 0.2476 - val_acc: 0.9287\n",
      "Epoch 8/100\n",
      "25569/25569 [==============================] - 2s 65us/step - loss: 0.2398 - acc: 0.9301 - val_loss: 0.2465 - val_acc: 0.9287\n",
      "Epoch 9/100\n",
      "25569/25569 [==============================] - 2s 63us/step - loss: 0.2393 - acc: 0.9301 - val_loss: 0.2479 - val_acc: 0.9287\n",
      "Epoch 10/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2388 - acc: 0.9301 - val_loss: 0.2476 - val_acc: 0.9287\n",
      "Epoch 11/100\n",
      "25569/25569 [==============================] - 2s 67us/step - loss: 0.2383 - acc: 0.9301 - val_loss: 0.2480 - val_acc: 0.9287\n",
      "Epoch 12/100\n",
      "25569/25569 [==============================] - 2s 67us/step - loss: 0.2376 - acc: 0.9301 - val_loss: 0.2470 - val_acc: 0.9287\n",
      "Epoch 13/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2370 - acc: 0.9301 - val_loss: 0.2471 - val_acc: 0.9287\n",
      "Epoch 14/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2368 - acc: 0.9301 - val_loss: 0.2466 - val_acc: 0.9287\n",
      "Epoch 15/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2354 - acc: 0.9301 - val_loss: 0.2468 - val_acc: 0.9287\n",
      "Epoch 16/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2350 - acc: 0.9301 - val_loss: 0.2474 - val_acc: 0.9287\n",
      "Epoch 17/100\n",
      "25569/25569 [==============================] - 1s 53us/step - loss: 0.2345 - acc: 0.9301 - val_loss: 0.2476 - val_acc: 0.9287\n",
      "Epoch 18/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2337 - acc: 0.9301 - val_loss: 0.2470 - val_acc: 0.9287\n",
      "Epoch 19/100\n",
      "25569/25569 [==============================] - 2s 61us/step - loss: 0.2331 - acc: 0.9301 - val_loss: 0.2467 - val_acc: 0.9287\n",
      "Epoch 20/100\n",
      "25569/25569 [==============================] - 2s 62us/step - loss: 0.2327 - acc: 0.9301 - val_loss: 0.2529 - val_acc: 0.9287\n",
      "Epoch 21/100\n",
      "25569/25569 [==============================] - 2s 77us/step - loss: 0.2325 - acc: 0.9301 - val_loss: 0.2466 - val_acc: 0.9287\n",
      "Epoch 22/100\n",
      "25569/25569 [==============================] - 2s 70us/step - loss: 0.2317 - acc: 0.9301 - val_loss: 0.2475 - val_acc: 0.9287\n",
      "Epoch 23/100\n",
      "25569/25569 [==============================] - 2s 70us/step - loss: 0.2311 - acc: 0.9301 - val_loss: 0.2481 - val_acc: 0.9287\n",
      "Epoch 24/100\n",
      "25569/25569 [==============================] - 1s 58us/step - loss: 0.2313 - acc: 0.9301 - val_loss: 0.2487 - val_acc: 0.9287\n",
      "Epoch 25/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2306 - acc: 0.9301 - val_loss: 0.2511 - val_acc: 0.9287\n",
      "Epoch 26/100\n",
      "25569/25569 [==============================] - 1s 58us/step - loss: 0.2300 - acc: 0.9301 - val_loss: 0.2473 - val_acc: 0.9287\n",
      "Epoch 27/100\n",
      "25569/25569 [==============================] - 2s 66us/step - loss: 0.2299 - acc: 0.9301 - val_loss: 0.2478 - val_acc: 0.9287\n",
      "Epoch 28/100\n",
      "25569/25569 [==============================] - 2s 69us/step - loss: 0.2297 - acc: 0.9301 - val_loss: 0.2466 - val_acc: 0.9287\n",
      "Epoch 29/100\n",
      "25569/25569 [==============================] - 2s 61us/step - loss: 0.2291 - acc: 0.9301 - val_loss: 0.2547 - val_acc: 0.9287\n",
      "Epoch 30/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2290 - acc: 0.9301 - val_loss: 0.2477 - val_acc: 0.9287\n",
      "Epoch 31/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2283 - acc: 0.9301 - val_loss: 0.2493 - val_acc: 0.9287\n",
      "Epoch 32/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2280 - acc: 0.9301 - val_loss: 0.2498 - val_acc: 0.9287\n",
      "Epoch 33/100\n",
      "25569/25569 [==============================] - 1s 56us/step - loss: 0.2278 - acc: 0.9321 - val_loss: 0.2494 - val_acc: 0.9276\n",
      "Epoch 34/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2271 - acc: 0.9330 - val_loss: 0.2478 - val_acc: 0.9265\n",
      "Epoch 35/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2270 - acc: 0.9333 - val_loss: 0.2513 - val_acc: 0.9255\n",
      "Epoch 36/100\n",
      "25569/25569 [==============================] - 2s 62us/step - loss: 0.2267 - acc: 0.9333 - val_loss: 0.2481 - val_acc: 0.9260\n",
      "Epoch 37/100\n",
      "25569/25569 [==============================] - 1s 58us/step - loss: 0.2264 - acc: 0.9331 - val_loss: 0.2508 - val_acc: 0.9270\n",
      "Epoch 38/100\n",
      "25569/25569 [==============================] - 2s 67us/step - loss: 0.2263 - acc: 0.9333 - val_loss: 0.2480 - val_acc: 0.9270\n",
      "Epoch 39/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2253 - acc: 0.9334 - val_loss: 0.2485 - val_acc: 0.9271\n",
      "Epoch 40/100\n",
      "25569/25569 [==============================] - 2s 95us/step - loss: 0.2247 - acc: 0.9341 - val_loss: 0.2478 - val_acc: 0.9273\n",
      "Epoch 41/100\n",
      "25569/25569 [==============================] - 2s 69us/step - loss: 0.2247 - acc: 0.9337 - val_loss: 0.2499 - val_acc: 0.9248\n",
      "Epoch 42/100\n",
      "25569/25569 [==============================] - 1s 58us/step - loss: 0.2239 - acc: 0.9338 - val_loss: 0.2518 - val_acc: 0.9269\n",
      "Epoch 43/100\n",
      "25569/25569 [==============================] - 2s 68us/step - loss: 0.2240 - acc: 0.9337 - val_loss: 0.2496 - val_acc: 0.9268\n",
      "Epoch 44/100\n",
      "25569/25569 [==============================] - 2s 61us/step - loss: 0.2239 - acc: 0.9342 - val_loss: 0.2489 - val_acc: 0.9259\n",
      "Epoch 45/100\n",
      "25569/25569 [==============================] - 2s 85us/step - loss: 0.2234 - acc: 0.9337 - val_loss: 0.2521 - val_acc: 0.9270\n",
      "Epoch 46/100\n",
      "25569/25569 [==============================] - 2s 79us/step - loss: 0.2235 - acc: 0.9345 - val_loss: 0.2487 - val_acc: 0.9266\n",
      "Epoch 47/100\n",
      "25569/25569 [==============================] - 1s 56us/step - loss: 0.2230 - acc: 0.9343 - val_loss: 0.2496 - val_acc: 0.9240\n",
      "Epoch 48/100\n",
      "25569/25569 [==============================] - 1s 53us/step - loss: 0.2230 - acc: 0.9337 - val_loss: 0.2522 - val_acc: 0.9252\n",
      "Epoch 49/100\n",
      "25569/25569 [==============================] - 1s 55us/step - loss: 0.2221 - acc: 0.9341 - val_loss: 0.2474 - val_acc: 0.9254\n",
      "Epoch 50/100\n",
      "25569/25569 [==============================] - 2s 69us/step - loss: 0.2228 - acc: 0.9344 - val_loss: 0.2492 - val_acc: 0.9251\n",
      "Epoch 51/100\n",
      "25569/25569 [==============================] - 1s 57us/step - loss: 0.2216 - acc: 0.9342 - val_loss: 0.2478 - val_acc: 0.9255\n",
      "Epoch 52/100\n",
      "25569/25569 [==============================] - 2s 68us/step - loss: 0.2213 - acc: 0.9344 - val_loss: 0.2514 - val_acc: 0.9246\n",
      "Epoch 53/100\n",
      "25569/25569 [==============================] - 2s 62us/step - loss: 0.2214 - acc: 0.9337 - val_loss: 0.2494 - val_acc: 0.9255\n",
      "Epoch 54/100\n",
      "25569/25569 [==============================] - 2s 62us/step - loss: 0.2207 - acc: 0.9345 - val_loss: 0.2486 - val_acc: 0.9243\n",
      "Epoch 55/100\n",
      "25569/25569 [==============================] - 3s 103us/step - loss: 0.2210 - acc: 0.9352 - val_loss: 0.2473 - val_acc: 0.9263\n",
      "Epoch 56/100\n",
      "25569/25569 [==============================] - 3s 98us/step - loss: 0.2213 - acc: 0.9341 - val_loss: 0.2498 - val_acc: 0.9247\n",
      "Epoch 57/100\n",
      "25569/25569 [==============================] - 2s 95us/step - loss: 0.2210 - acc: 0.9344 - val_loss: 0.2491 - val_acc: 0.9246\n",
      "Epoch 58/100\n",
      "25569/25569 [==============================] - 2s 94us/step - loss: 0.2206 - acc: 0.9343 - val_loss: 0.2513 - val_acc: 0.9255\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25569/25569 [==============================] - 2s 88us/step - loss: 0.2206 - acc: 0.9344 - val_loss: 0.2489 - val_acc: 0.9226\n",
      "Epoch 60/100\n",
      "25569/25569 [==============================] - 2s 93us/step - loss: 0.2199 - acc: 0.9351 - val_loss: 0.2488 - val_acc: 0.9254\n",
      "Epoch 61/100\n",
      "25569/25569 [==============================] - 2s 96us/step - loss: 0.2195 - acc: 0.9349 - val_loss: 0.2505 - val_acc: 0.9246\n",
      "Epoch 62/100\n",
      "25569/25569 [==============================] - 2s 97us/step - loss: 0.2196 - acc: 0.9352 - val_loss: 0.2490 - val_acc: 0.9257\n",
      "Epoch 63/100\n",
      "25569/25569 [==============================] - 3s 99us/step - loss: 0.2194 - acc: 0.9354 - val_loss: 0.2486 - val_acc: 0.9253\n",
      "Epoch 64/100\n",
      "25569/25569 [==============================] - 2s 85us/step - loss: 0.2190 - acc: 0.9351 - val_loss: 0.2526 - val_acc: 0.9252\n",
      "Epoch 65/100\n",
      "25569/25569 [==============================] - 2s 84us/step - loss: 0.2191 - acc: 0.9349 - val_loss: 0.2486 - val_acc: 0.9255\n",
      "Epoch 66/100\n",
      "25569/25569 [==============================] - 2s 81us/step - loss: 0.2188 - acc: 0.9349 - val_loss: 0.2513 - val_acc: 0.9252\n",
      "Epoch 67/100\n",
      "25569/25569 [==============================] - 2s 82us/step - loss: 0.2177 - acc: 0.9355 - val_loss: 0.2503 - val_acc: 0.9244\n",
      "Epoch 68/100\n",
      "25569/25569 [==============================] - 2s 84us/step - loss: 0.2186 - acc: 0.9349 - val_loss: 0.2501 - val_acc: 0.9241\n",
      "Epoch 69/100\n",
      "25569/25569 [==============================] - 2s 83us/step - loss: 0.2182 - acc: 0.9355 - val_loss: 0.2493 - val_acc: 0.9244\n",
      "Epoch 70/100\n",
      "25569/25569 [==============================] - 1s 53us/step - loss: 0.2174 - acc: 0.9355 - val_loss: 0.2530 - val_acc: 0.9236\n",
      "Epoch 71/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2170 - acc: 0.9356 - val_loss: 0.2498 - val_acc: 0.9253\n",
      "Epoch 72/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2165 - acc: 0.9357 - val_loss: 0.2525 - val_acc: 0.9219\n",
      "Epoch 73/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2177 - acc: 0.9354 - val_loss: 0.2494 - val_acc: 0.9242\n",
      "Epoch 74/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2173 - acc: 0.9353 - val_loss: 0.2510 - val_acc: 0.9221\n",
      "Epoch 75/100\n",
      "25569/25569 [==============================] - 1s 50us/step - loss: 0.2159 - acc: 0.9355 - val_loss: 0.2506 - val_acc: 0.9230\n",
      "Epoch 76/100\n",
      "25569/25569 [==============================] - 2s 74us/step - loss: 0.2156 - acc: 0.9356 - val_loss: 0.2511 - val_acc: 0.9224\n",
      "Epoch 77/100\n",
      "25569/25569 [==============================] - 1s 49us/step - loss: 0.2153 - acc: 0.9357 - val_loss: 0.2540 - val_acc: 0.9235\n",
      "Epoch 78/100\n",
      "25569/25569 [==============================] - 1s 49us/step - loss: 0.2151 - acc: 0.9361 - val_loss: 0.2548 - val_acc: 0.9199\n",
      "Epoch 79/100\n",
      "25569/25569 [==============================] - 1s 48us/step - loss: 0.2150 - acc: 0.9360 - val_loss: 0.2533 - val_acc: 0.9223\n",
      "Epoch 80/100\n",
      "25569/25569 [==============================] - 1s 48us/step - loss: 0.2143 - acc: 0.9362 - val_loss: 0.2529 - val_acc: 0.9237\n",
      "Epoch 81/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2141 - acc: 0.9364 - val_loss: 0.2522 - val_acc: 0.9229\n",
      "Epoch 82/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2139 - acc: 0.9365 - val_loss: 0.2522 - val_acc: 0.9268\n",
      "Epoch 83/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2135 - acc: 0.9363 - val_loss: 0.2561 - val_acc: 0.9218\n",
      "Epoch 84/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2136 - acc: 0.9364 - val_loss: 0.2530 - val_acc: 0.9224\n",
      "Epoch 85/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2137 - acc: 0.9359 - val_loss: 0.2555 - val_acc: 0.9235\n",
      "Epoch 86/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2127 - acc: 0.9364 - val_loss: 0.2533 - val_acc: 0.9239\n",
      "Epoch 87/100\n",
      "25569/25569 [==============================] - 1s 47us/step - loss: 0.2129 - acc: 0.9361 - val_loss: 0.2552 - val_acc: 0.9187\n",
      "Epoch 88/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2119 - acc: 0.9374 - val_loss: 0.2569 - val_acc: 0.9210\n",
      "Epoch 89/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2125 - acc: 0.9361 - val_loss: 0.2543 - val_acc: 0.9233\n",
      "Epoch 90/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2116 - acc: 0.9369 - val_loss: 0.2565 - val_acc: 0.9230\n",
      "Epoch 91/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2119 - acc: 0.9367 - val_loss: 0.2568 - val_acc: 0.9219\n",
      "Epoch 92/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2114 - acc: 0.9370 - val_loss: 0.2544 - val_acc: 0.9234\n",
      "Epoch 93/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2111 - acc: 0.9368 - val_loss: 0.2574 - val_acc: 0.9222\n",
      "Epoch 94/100\n",
      "25569/25569 [==============================] - 1s 46us/step - loss: 0.2101 - acc: 0.9374 - val_loss: 0.2563 - val_acc: 0.9246\n",
      "Epoch 95/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2107 - acc: 0.9373 - val_loss: 0.2568 - val_acc: 0.9258\n",
      "Epoch 96/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2100 - acc: 0.9373 - val_loss: 0.2569 - val_acc: 0.9200\n",
      "Epoch 97/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2102 - acc: 0.9369 - val_loss: 0.2559 - val_acc: 0.9232\n",
      "Epoch 98/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2093 - acc: 0.9381 - val_loss: 0.2562 - val_acc: 0.9240\n",
      "Epoch 99/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2098 - acc: 0.9375 - val_loss: 0.2557 - val_acc: 0.9241\n",
      "Epoch 100/100\n",
      "25569/25569 [==============================] - 1s 45us/step - loss: 0.2093 - acc: 0.9374 - val_loss: 0.2538 - val_acc: 0.9237\n"
     ]
    }
   ],
   "source": [
    "checker = classifier.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_label = classifier.predict(X_test)\n",
    "y_pred_test=np.argmax(Y_pred_test_label,axis =1)\n",
    "y_pred_test\n",
    "Y_pred_train_label = classifier.predict(X_train)\n",
    "y_pred_train = np.argmax(Y_pred_train_label,axis=1)\n",
    "Y_test_true = Y_test_org.astype(np.int)\n",
    "Y_train_true = Y_train_org.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5937\n",
      "          1       0.37      0.10      0.16       456\n",
      "\n",
      "avg / total       0.89      0.92      0.90      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_true,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97     23783\n",
      "          1       0.76      0.21      0.33      1786\n",
      "\n",
      "avg / total       0.93      0.94      0.92     25569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train_true,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  \n",
      " [[23663  1414]\n",
      " [  120   372]]\n",
      "\n",
      "Test:  \n",
      " [[5860  411]\n",
      " [  77   45]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN:  \\n\",confusion_matrix(y_pred_train,Y_train_true))\n",
    "print(\"\\nTest:  \\n\",confusion_matrix(y_pred_test,Y_test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
