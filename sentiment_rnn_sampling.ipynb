{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       2242   2242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 =  df.query('label==0')\n",
    "df_class_1 =  df.query('label==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1],ignore_index=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4484, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  tweet\n",
       "label             \n",
       "0      2242   2242\n",
       "1      2242   2242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_under['tweet']\n",
    "Y = df_under['label']\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ', lower=True, char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "# add padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @user lmfao pathetic #soit   #growup #funny #noonethere #iknowwhoitis ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82â\\x80¦'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['tweet'], key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel(\"No. of components\")\n",
    "plt.ylabel(\"cummulative explained Variance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(LSTM(units=40, activation='relu',return_sequences= True, input_shape=(None, 35)))\n",
    "classifier.add(Dropout(rate=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(LSTM(units=20, return_sequences= True,activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(LSTM(units=20,activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(Dense(units = 2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='rmsprop',metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_e = OneHotEncoder()\n",
    "Y_train_org = Y_train\n",
    "Y_test_org = Y_test\n",
    "Y_train =np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "y_e.fit(Y_train)\n",
    "Y_train = y_e.transform(Y_train)\n",
    "Y_test = y_e.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 897 samples\n",
      "Epoch 1/200\n",
      "3587/3587 [==============================] - 3s 847us/step - loss: 0.6921 - acc: 0.5326 - val_loss: 0.6894 - val_acc: 0.5753\n",
      "Epoch 2/200\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.6835 - acc: 0.606 - 1s 205us/step - loss: 0.6838 - acc: 0.6075 - val_loss: 0.6776 - val_acc: 0.6678\n",
      "Epoch 3/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.6689 - acc: 0.6553 - val_loss: 0.6852 - val_acc: 0.6683\n",
      "Epoch 4/200\n",
      "3587/3587 [==============================] - 1s 208us/step - loss: 0.6629 - acc: 0.6645 - val_loss: 0.6600 - val_acc: 0.6695\n",
      "Epoch 5/200\n",
      "3587/3587 [==============================] - 1s 216us/step - loss: 0.6443 - acc: 0.6614 - val_loss: 0.6671 - val_acc: 0.6711\n",
      "Epoch 6/200\n",
      "3587/3587 [==============================] - 1s 216us/step - loss: 0.6400 - acc: 0.6664 - val_loss: 0.6523 - val_acc: 0.6722\n",
      "Epoch 7/200\n",
      "3587/3587 [==============================] - 1s 222us/step - loss: 0.6367 - acc: 0.6741 - val_loss: 0.6452 - val_acc: 0.6745\n",
      "Epoch 8/200\n",
      "3587/3587 [==============================] - 1s 239us/step - loss: 0.6372 - acc: 0.6708 - val_loss: 0.6429 - val_acc: 0.6773\n",
      "Epoch 9/200\n",
      "3587/3587 [==============================] - 1s 227us/step - loss: 0.6298 - acc: 0.6731 - val_loss: 0.6442 - val_acc: 0.6828\n",
      "Epoch 10/200\n",
      "3587/3587 [==============================] - 1s 240us/step - loss: 0.6286 - acc: 0.6783 - val_loss: 0.6377 - val_acc: 0.6739\n",
      "Epoch 11/200\n",
      "3587/3587 [==============================] - 1s 243us/step - loss: 0.6247 - acc: 0.6807 - val_loss: 0.6367 - val_acc: 0.6812\n",
      "Epoch 12/200\n",
      "3587/3587 [==============================] - 1s 225us/step - loss: 0.6225 - acc: 0.6790 - val_loss: 0.6355 - val_acc: 0.6773\n",
      "Epoch 13/200\n",
      "3587/3587 [==============================] - 1s 237us/step - loss: 0.6202 - acc: 0.6872 - val_loss: 0.6334 - val_acc: 0.6806\n",
      "Epoch 14/200\n",
      "3587/3587 [==============================] - 1s 237us/step - loss: 0.6249 - acc: 0.6834 - val_loss: 0.6299 - val_acc: 0.6778\n",
      "Epoch 15/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.6113 - acc: 0.6878 - val_loss: 0.6326 - val_acc: 0.6839\n",
      "Epoch 16/200\n",
      "3587/3587 [==============================] - 1s 225us/step - loss: 0.6091 - acc: 0.6917 - val_loss: 0.6285 - val_acc: 0.6767\n",
      "Epoch 17/200\n",
      "3587/3587 [==============================] - 1s 235us/step - loss: 0.6067 - acc: 0.6963 - val_loss: 0.6297 - val_acc: 0.6851\n",
      "Epoch 18/200\n",
      "3587/3587 [==============================] - 1s 233us/step - loss: 0.6031 - acc: 0.6915 - val_loss: 0.6340 - val_acc: 0.6784\n",
      "Epoch 19/200\n",
      "3587/3587 [==============================] - 1s 239us/step - loss: 0.6061 - acc: 0.6885 - val_loss: 0.6296 - val_acc: 0.6784\n",
      "Epoch 20/200\n",
      "3587/3587 [==============================] - 1s 238us/step - loss: 0.6002 - acc: 0.7000 - val_loss: 0.6346 - val_acc: 0.6834\n",
      "Epoch 21/200\n",
      "3587/3587 [==============================] - 1s 212us/step - loss: 0.6014 - acc: 0.7013 - val_loss: 0.6293 - val_acc: 0.6873\n",
      "Epoch 22/200\n",
      "3587/3587 [==============================] - 1s 219us/step - loss: 0.5920 - acc: 0.7109 - val_loss: 0.6287 - val_acc: 0.6873\n",
      "Epoch 23/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.5968 - acc: 0.7063 - val_loss: 0.6267 - val_acc: 0.6890\n",
      "Epoch 24/200\n",
      "3587/3587 [==============================] - 1s 218us/step - loss: 0.5909 - acc: 0.7095 - val_loss: 0.6323 - val_acc: 0.6890\n",
      "Epoch 25/200\n",
      "3587/3587 [==============================] - 1s 223us/step - loss: 0.5927 - acc: 0.7087 - val_loss: 0.6281 - val_acc: 0.6890\n",
      "Epoch 26/200\n",
      "3587/3587 [==============================] - 1s 225us/step - loss: 0.5856 - acc: 0.7141 - val_loss: 0.6352 - val_acc: 0.6895\n",
      "Epoch 27/200\n",
      "3587/3587 [==============================] - 1s 222us/step - loss: 0.5858 - acc: 0.7177 - val_loss: 0.6365 - val_acc: 0.6895\n",
      "Epoch 28/200\n",
      "3587/3587 [==============================] - 1s 221us/step - loss: 0.5848 - acc: 0.7105 - val_loss: 0.6309 - val_acc: 0.6923\n",
      "Epoch 29/200\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.5848 - acc: 0.7161 - val_loss: 0.6404 - val_acc: 0.6884\n",
      "Epoch 30/200\n",
      "3587/3587 [==============================] - 1s 223us/step - loss: 0.5864 - acc: 0.7105 - val_loss: 0.6298 - val_acc: 0.6856\n",
      "Epoch 31/200\n",
      "3587/3587 [==============================] - 1s 229us/step - loss: 0.5848 - acc: 0.7165 - val_loss: 0.6421 - val_acc: 0.6873\n",
      "Epoch 32/200\n",
      "3587/3587 [==============================] - 1s 229us/step - loss: 0.5783 - acc: 0.7190 - val_loss: 0.6318 - val_acc: 0.6923\n",
      "Epoch 33/200\n",
      "3587/3587 [==============================] - 1s 237us/step - loss: 0.5803 - acc: 0.7183 - val_loss: 0.6349 - val_acc: 0.6851\n",
      "Epoch 34/200\n",
      "3587/3587 [==============================] - 1s 220us/step - loss: 0.5739 - acc: 0.7201 - val_loss: 0.6541 - val_acc: 0.6823\n",
      "Epoch 35/200\n",
      "3587/3587 [==============================] - 1s 232us/step - loss: 0.5724 - acc: 0.7201 - val_loss: 0.6506 - val_acc: 0.6839\n",
      "Epoch 36/200\n",
      "3587/3587 [==============================] - 1s 279us/step - loss: 0.5749 - acc: 0.7293 - val_loss: 0.6488 - val_acc: 0.6878\n",
      "Epoch 37/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.5721 - acc: 0.7271 - val_loss: 0.6479 - val_acc: 0.6895\n",
      "Epoch 38/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.5701 - acc: 0.7250 - val_loss: 0.6463 - val_acc: 0.6890\n",
      "Epoch 39/200\n",
      "3587/3587 [==============================] - 1s 264us/step - loss: 0.5716 - acc: 0.7306 - val_loss: 0.6391 - val_acc: 0.6878\n",
      "Epoch 40/200\n",
      "3587/3587 [==============================] - 1s 264us/step - loss: 0.5717 - acc: 0.7230 - val_loss: 0.6459 - val_acc: 0.6828\n",
      "Epoch 41/200\n",
      "3587/3587 [==============================] - 1s 255us/step - loss: 0.5661 - acc: 0.7255 - val_loss: 0.6561 - val_acc: 0.6812\n",
      "Epoch 42/200\n",
      "3587/3587 [==============================] - 1s 250us/step - loss: 0.5722 - acc: 0.7205 - val_loss: 0.6385 - val_acc: 0.6817\n",
      "Epoch 43/200\n",
      "3587/3587 [==============================] - 1s 257us/step - loss: 0.5628 - acc: 0.7319 - val_loss: 0.6492 - val_acc: 0.6823\n",
      "Epoch 44/200\n",
      "3587/3587 [==============================] - 1s 266us/step - loss: 0.5629 - acc: 0.7324 - val_loss: 0.6595 - val_acc: 0.6834\n",
      "Epoch 45/200\n",
      "3587/3587 [==============================] - 1s 236us/step - loss: 0.5584 - acc: 0.7310 - val_loss: 0.6584 - val_acc: 0.6895\n",
      "Epoch 46/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.5570 - acc: 0.7290 - val_loss: 0.6698 - val_acc: 0.6918\n",
      "Epoch 47/200\n",
      "3587/3587 [==============================] - 1s 240us/step - loss: 0.5544 - acc: 0.7326 - val_loss: 0.6644 - val_acc: 0.6884\n",
      "Epoch 48/200\n",
      "3587/3587 [==============================] - 1s 236us/step - loss: 0.5584 - acc: 0.7354 - val_loss: 0.6664 - val_acc: 0.6906\n",
      "Epoch 49/200\n",
      "3587/3587 [==============================] - 1s 237us/step - loss: 0.5547 - acc: 0.7395 - val_loss: 0.6744 - val_acc: 0.6856\n",
      "Epoch 50/200\n",
      "3587/3587 [==============================] - 1s 247us/step - loss: 0.5580 - acc: 0.7322 - val_loss: 0.6518 - val_acc: 0.6945\n",
      "Epoch 51/200\n",
      "3587/3587 [==============================] - 1s 257us/step - loss: 0.5462 - acc: 0.7400 - val_loss: 0.6750 - val_acc: 0.6918\n",
      "Epoch 52/200\n",
      "3587/3587 [==============================] - 1s 267us/step - loss: 0.5433 - acc: 0.7379 - val_loss: 0.6938 - val_acc: 0.6912\n",
      "Epoch 53/200\n",
      "3587/3587 [==============================] - 1s 254us/step - loss: 0.5487 - acc: 0.7403 - val_loss: 0.6872 - val_acc: 0.6873\n",
      "Epoch 54/200\n",
      "3587/3587 [==============================] - 1s 255us/step - loss: 0.5503 - acc: 0.7400 - val_loss: 0.6770 - val_acc: 0.6929\n",
      "Epoch 55/200\n",
      "3587/3587 [==============================] - 1s 254us/step - loss: 0.5539 - acc: 0.7378 - val_loss: 0.6752 - val_acc: 0.6968\n",
      "Epoch 56/200\n",
      "3587/3587 [==============================] - 1s 253us/step - loss: 0.5461 - acc: 0.7363 - val_loss: 0.6897 - val_acc: 0.6984\n",
      "Epoch 57/200\n",
      "3587/3587 [==============================] - 1s 259us/step - loss: 0.5449 - acc: 0.7446 - val_loss: 0.7003 - val_acc: 0.6984\n",
      "Epoch 58/200\n",
      "3587/3587 [==============================] - 1s 262us/step - loss: 0.5377 - acc: 0.7438 - val_loss: 0.6720 - val_acc: 0.6923\n",
      "Epoch 59/200\n",
      "3587/3587 [==============================] - 1s 262us/step - loss: 0.5372 - acc: 0.7480 - val_loss: 0.6796 - val_acc: 0.6901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.5395 - acc: 0.7382 - val_loss: 0.6952 - val_acc: 0.6957\n",
      "Epoch 61/200\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.5367 - acc: 0.7451 - val_loss: 0.6764 - val_acc: 0.7040\n",
      "Epoch 62/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5434 - acc: 0.7428 - val_loss: 0.6660 - val_acc: 0.6918\n",
      "Epoch 63/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.5270 - acc: 0.7499 - val_loss: 0.6811 - val_acc: 0.6929\n",
      "Epoch 64/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5315 - acc: 0.7446 - val_loss: 0.6810 - val_acc: 0.6979\n",
      "Epoch 65/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.5299 - acc: 0.7505 - val_loss: 0.6893 - val_acc: 0.6962\n",
      "Epoch 66/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.5348 - acc: 0.7463 - val_loss: 0.6778 - val_acc: 0.6979\n",
      "Epoch 67/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.5371 - acc: 0.7506 - val_loss: 0.6660 - val_acc: 0.6906\n",
      "Epoch 68/200\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.5165 - acc: 0.7530 - val_loss: 0.6921 - val_acc: 0.6990\n",
      "Epoch 69/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.5292 - acc: 0.7497 - val_loss: 0.6732 - val_acc: 0.6951\n",
      "Epoch 70/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.5167 - acc: 0.7655 - val_loss: 0.6726 - val_acc: 0.7001\n",
      "Epoch 71/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.5237 - acc: 0.7563 - val_loss: 0.6786 - val_acc: 0.7001\n",
      "Epoch 72/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.5203 - acc: 0.7494 - val_loss: 0.6685 - val_acc: 0.6951\n",
      "Epoch 73/200\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.5245 - acc: 0.7508 - val_loss: 0.6780 - val_acc: 0.6990\n",
      "Epoch 74/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.5097 - acc: 0.7587 - val_loss: 0.6757 - val_acc: 0.7079\n",
      "Epoch 75/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.5147 - acc: 0.7589 - val_loss: 0.6923 - val_acc: 0.6957\n",
      "Epoch 76/200\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.5211 - acc: 0.7548 - val_loss: 0.6836 - val_acc: 0.7051\n",
      "Epoch 77/200\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.5242 - acc: 0.7570 - val_loss: 0.6621 - val_acc: 0.7101\n",
      "Epoch 78/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.5132 - acc: 0.7582 - val_loss: 0.6690 - val_acc: 0.7040\n",
      "Epoch 79/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.5119 - acc: 0.7547 - val_loss: 0.6824 - val_acc: 0.7107\n",
      "Epoch 80/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.5011 - acc: 0.7639 - val_loss: 0.6837 - val_acc: 0.7046\n",
      "Epoch 81/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.5087 - acc: 0.7591 - val_loss: 0.6759 - val_acc: 0.7068\n",
      "Epoch 82/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.5124 - acc: 0.7572 - val_loss: 0.6651 - val_acc: 0.7062\n",
      "Epoch 83/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5169 - acc: 0.7626 - val_loss: 0.6622 - val_acc: 0.7146\n",
      "Epoch 84/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.4987 - acc: 0.7664 - val_loss: 0.6904 - val_acc: 0.7140\n",
      "Epoch 85/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.5069 - acc: 0.7549 - val_loss: 0.6749 - val_acc: 0.7135\n",
      "Epoch 86/200\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.4984 - acc: 0.7619 - val_loss: 0.6749 - val_acc: 0.7140\n",
      "Epoch 87/200\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.4928 - acc: 0.7753 - val_loss: 0.6921 - val_acc: 0.7124\n",
      "Epoch 88/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.5109 - acc: 0.7600 - val_loss: 0.6691 - val_acc: 0.7124\n",
      "Epoch 89/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4975 - acc: 0.7689 - val_loss: 0.6751 - val_acc: 0.7113\n",
      "Epoch 90/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4888 - acc: 0.7735 - val_loss: 0.6751 - val_acc: 0.7124\n",
      "Epoch 91/200\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.4948 - acc: 0.7661 - val_loss: 0.6830 - val_acc: 0.7068\n",
      "Epoch 92/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4975 - acc: 0.7662 - val_loss: 0.6883 - val_acc: 0.7062\n",
      "Epoch 93/200\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.4849 - acc: 0.7728 - val_loss: 0.6905 - val_acc: 0.7152\n",
      "Epoch 94/200\n",
      "3587/3587 [==============================] - 1s 196us/step - loss: 0.4937 - acc: 0.7668 - val_loss: 0.6894 - val_acc: 0.7174\n",
      "Epoch 95/200\n",
      "3587/3587 [==============================] - 1s 201us/step - loss: 0.4863 - acc: 0.7757 - val_loss: 0.6828 - val_acc: 0.7113\n",
      "Epoch 96/200\n",
      "3587/3587 [==============================] - 1s 206us/step - loss: 0.4892 - acc: 0.7725 - val_loss: 0.6904 - val_acc: 0.7107\n",
      "Epoch 97/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4766 - acc: 0.7786 - val_loss: 0.6792 - val_acc: 0.7179\n",
      "Epoch 98/200\n",
      "3587/3587 [==============================] - 1s 199us/step - loss: 0.4719 - acc: 0.7785 - val_loss: 0.7058 - val_acc: 0.7146\n",
      "Epoch 99/200\n",
      "3587/3587 [==============================] - 1s 220us/step - loss: 0.4795 - acc: 0.7777 - val_loss: 0.6975 - val_acc: 0.7258\n",
      "Epoch 100/200\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.4797 - acc: 0.7798 - val_loss: 0.6806 - val_acc: 0.7191\n",
      "Epoch 101/200\n",
      "3587/3587 [==============================] - 1s 218us/step - loss: 0.4689 - acc: 0.7795 - val_loss: 0.6999 - val_acc: 0.7157\n",
      "Epoch 102/200\n",
      "3587/3587 [==============================] - 1s 220us/step - loss: 0.4728 - acc: 0.7750 - val_loss: 0.6967 - val_acc: 0.7213\n",
      "Epoch 103/200\n",
      "3587/3587 [==============================] - 1s 213us/step - loss: 0.4710 - acc: 0.7831 - val_loss: 0.7041 - val_acc: 0.7213\n",
      "Epoch 104/200\n",
      "3587/3587 [==============================] - 1s 210us/step - loss: 0.4616 - acc: 0.7816 - val_loss: 0.7206 - val_acc: 0.7202\n",
      "Epoch 105/200\n",
      "3587/3587 [==============================] - 1s 219us/step - loss: 0.4714 - acc: 0.7722 - val_loss: 0.6996 - val_acc: 0.7174\n",
      "Epoch 106/200\n",
      "3587/3587 [==============================] - 1s 217us/step - loss: 0.4681 - acc: 0.7825 - val_loss: 0.7015 - val_acc: 0.7146\n",
      "Epoch 107/200\n",
      "3587/3587 [==============================] - 1s 204us/step - loss: 0.4683 - acc: 0.7892 - val_loss: 0.6955 - val_acc: 0.7291\n",
      "Epoch 108/200\n",
      "3587/3587 [==============================] - 1s 218us/step - loss: 0.4654 - acc: 0.7817 - val_loss: 0.7007 - val_acc: 0.7174\n",
      "Epoch 109/200\n",
      "3587/3587 [==============================] - 1s 217us/step - loss: 0.4604 - acc: 0.7774 - val_loss: 0.7005 - val_acc: 0.7157\n",
      "Epoch 110/200\n",
      "3587/3587 [==============================] - 1s 222us/step - loss: 0.4713 - acc: 0.7806 - val_loss: 0.7055 - val_acc: 0.7336\n",
      "Epoch 111/200\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.4690 - acc: 0.7739 - val_loss: 0.7018 - val_acc: 0.7319\n",
      "Epoch 112/200\n",
      "3587/3587 [==============================] - 1s 215us/step - loss: 0.4739 - acc: 0.7782 - val_loss: 0.6942 - val_acc: 0.7235\n",
      "Epoch 113/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4621 - acc: 0.7844 - val_loss: 0.7131 - val_acc: 0.7291\n",
      "Epoch 114/200\n",
      "3587/3587 [==============================] - 1s 207us/step - loss: 0.4592 - acc: 0.7825 - val_loss: 0.7244 - val_acc: 0.7224\n",
      "Epoch 115/200\n",
      "3587/3587 [==============================] - 1s 209us/step - loss: 0.4656 - acc: 0.7813 - val_loss: 0.7237 - val_acc: 0.7235\n",
      "Epoch 116/200\n",
      "3587/3587 [==============================] - 1s 213us/step - loss: 0.4520 - acc: 0.7842 - val_loss: 0.7266 - val_acc: 0.7263\n",
      "Epoch 117/200\n",
      "3587/3587 [==============================] - 1s 221us/step - loss: 0.4449 - acc: 0.7874 - val_loss: 0.7179 - val_acc: 0.7285\n",
      "Epoch 118/200\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.4536 - acc: 0.7837 - val_loss: 0.7292 - val_acc: 0.7341\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.4560 - acc: 0.7834 - val_loss: 0.7153 - val_acc: 0.7285\n",
      "Epoch 120/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4581 - acc: 0.7852 - val_loss: 0.7048 - val_acc: 0.7246\n",
      "Epoch 121/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.4426 - acc: 0.7906 - val_loss: 0.7419 - val_acc: 0.7313\n",
      "Epoch 122/200\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.4545 - acc: 0.7883 - val_loss: 0.7240 - val_acc: 0.7308\n",
      "Epoch 123/200\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.4479 - acc: 0.7887 - val_loss: 0.7133 - val_acc: 0.7258\n",
      "Epoch 124/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.7405 - val_acc: 0.7269\n",
      "Epoch 125/200\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.4501 - acc: 0.7837 - val_loss: 0.7311 - val_acc: 0.7291\n",
      "Epoch 126/200\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.4495 - acc: 0.7898 - val_loss: 0.7098 - val_acc: 0.7330\n",
      "Epoch 127/200\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.4574 - acc: 0.7908 - val_loss: 0.7034 - val_acc: 0.7341\n",
      "Epoch 128/200\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.4403 - acc: 0.7904 - val_loss: 0.7241 - val_acc: 0.7386\n",
      "Epoch 129/200\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.4393 - acc: 0.7890 - val_loss: 0.7248 - val_acc: 0.7408\n",
      "Epoch 130/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4465 - acc: 0.7848 - val_loss: 0.7221 - val_acc: 0.7324\n",
      "Epoch 131/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4353 - acc: 0.7941 - val_loss: 0.7490 - val_acc: 0.7313\n",
      "Epoch 132/200\n",
      "3587/3587 [==============================] - 1s 201us/step - loss: 0.4279 - acc: 0.8016 - val_loss: 0.7505 - val_acc: 0.7419\n",
      "Epoch 133/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.4496 - acc: 0.7845 - val_loss: 0.7294 - val_acc: 0.7347\n",
      "Epoch 134/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.4434 - acc: 0.7929 - val_loss: 0.7372 - val_acc: 0.7425\n",
      "Epoch 135/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4313 - acc: 0.7997 - val_loss: 0.7391 - val_acc: 0.7358\n",
      "Epoch 136/200\n",
      "3587/3587 [==============================] - 1s 199us/step - loss: 0.4269 - acc: 0.8005 - val_loss: 0.7284 - val_acc: 0.7402\n",
      "Epoch 137/200\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.4378 - acc: 0.7989 - val_loss: 0.7358 - val_acc: 0.7436\n",
      "Epoch 138/200\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.4382 - acc: 0.7916 - val_loss: 0.7244 - val_acc: 0.7302\n",
      "Epoch 139/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4317 - acc: 0.7945 - val_loss: 0.7273 - val_acc: 0.7436\n",
      "Epoch 140/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4401 - acc: 0.7922 - val_loss: 0.7195 - val_acc: 0.7352\n",
      "Epoch 141/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.4448 - acc: 0.7913 - val_loss: 0.7341 - val_acc: 0.7324\n",
      "Epoch 142/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4371 - acc: 0.7952 - val_loss: 0.7244 - val_acc: 0.7319\n",
      "Epoch 143/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4358 - acc: 0.7955 - val_loss: 0.7087 - val_acc: 0.7330\n",
      "Epoch 144/200\n",
      "3587/3587 [==============================] - 1s 215us/step - loss: 0.4319 - acc: 0.7998 - val_loss: 0.7090 - val_acc: 0.7375\n",
      "Epoch 145/200\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.4313 - acc: 0.7963 - val_loss: 0.7019 - val_acc: 0.7358\n",
      "Epoch 146/200\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.4324 - acc: 0.7940 - val_loss: 0.7176 - val_acc: 0.7347\n",
      "Epoch 147/200\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.4324 - acc: 0.7983 - val_loss: 0.7153 - val_acc: 0.7391\n",
      "Epoch 148/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4301 - acc: 0.8004 - val_loss: 0.7092 - val_acc: 0.7419\n",
      "Epoch 149/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4287 - acc: 0.7961 - val_loss: 0.6951 - val_acc: 0.7375\n",
      "Epoch 150/200\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.4320 - acc: 0.7994 - val_loss: 0.6986 - val_acc: 0.7436\n",
      "Epoch 151/200\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.4295 - acc: 0.7950 - val_loss: 0.7090 - val_acc: 0.7386\n",
      "Epoch 152/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4197 - acc: 0.8030 - val_loss: 0.7235 - val_acc: 0.7425\n",
      "Epoch 153/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4378 - acc: 0.7976 - val_loss: 0.7175 - val_acc: 0.7425\n",
      "Epoch 154/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4170 - acc: 0.8040 - val_loss: 0.7031 - val_acc: 0.7425\n",
      "Epoch 155/200\n",
      "3587/3587 [==============================] - 1s 206us/step - loss: 0.4199 - acc: 0.8044 - val_loss: 0.7039 - val_acc: 0.7419\n",
      "Epoch 156/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4204 - acc: 0.8049 - val_loss: 0.7164 - val_acc: 0.7402\n",
      "Epoch 157/200\n",
      "3587/3587 [==============================] - 1s 215us/step - loss: 0.4161 - acc: 0.8007 - val_loss: 0.7083 - val_acc: 0.7464\n",
      "Epoch 158/200\n",
      "3587/3587 [==============================] - 1s 204us/step - loss: 0.4228 - acc: 0.8085 - val_loss: 0.7122 - val_acc: 0.7419\n",
      "Epoch 159/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4240 - acc: 0.7986 - val_loss: 0.7152 - val_acc: 0.7469\n",
      "Epoch 160/200\n",
      "3587/3587 [==============================] - 1s 207us/step - loss: 0.4179 - acc: 0.8071 - val_loss: 0.7209 - val_acc: 0.7469\n",
      "Epoch 161/200\n",
      "3587/3587 [==============================] - 1s 201us/step - loss: 0.4156 - acc: 0.8030 - val_loss: 0.7301 - val_acc: 0.7425\n",
      "Epoch 162/200\n",
      "3587/3587 [==============================] - 1s 206us/step - loss: 0.4113 - acc: 0.8050 - val_loss: 0.7194 - val_acc: 0.7453\n",
      "Epoch 163/200\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.7350 - val_acc: 0.7414\n",
      "Epoch 164/200\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4122 - acc: 0.8022 - val_loss: 0.7091 - val_acc: 0.7458\n",
      "Epoch 165/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.4042 - acc: 0.8111 - val_loss: 0.7401 - val_acc: 0.7391\n",
      "Epoch 166/200\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.4204 - acc: 0.8035 - val_loss: 0.7406 - val_acc: 0.7358\n",
      "Epoch 167/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.4262 - acc: 0.8036 - val_loss: 0.7562 - val_acc: 0.7380\n",
      "Epoch 168/200\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.4178 - acc: 0.8023 - val_loss: 0.7442 - val_acc: 0.7347\n",
      "Epoch 169/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4239 - acc: 0.7975 - val_loss: 0.7417 - val_acc: 0.7492\n",
      "Epoch 170/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4114 - acc: 0.8015 - val_loss: 0.7430 - val_acc: 0.7464\n",
      "Epoch 171/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4170 - acc: 0.8014 - val_loss: 0.7296 - val_acc: 0.7508\n",
      "Epoch 172/200\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.4204 - acc: 0.8022 - val_loss: 0.7360 - val_acc: 0.7447\n",
      "Epoch 173/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.4150 - acc: 0.8057 - val_loss: 0.7213 - val_acc: 0.7464\n",
      "Epoch 174/200\n",
      "3587/3587 [==============================] - 1s 199us/step - loss: 0.4136 - acc: 0.8068 - val_loss: 0.7295 - val_acc: 0.7453\n",
      "Epoch 175/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4084 - acc: 0.8040 - val_loss: 0.7231 - val_acc: 0.7425\n",
      "Epoch 176/200\n",
      "3587/3587 [==============================] - 1s 207us/step - loss: 0.4190 - acc: 0.8028 - val_loss: 0.7400 - val_acc: 0.7414\n",
      "Epoch 177/200\n",
      "3587/3587 [==============================] - 1s 212us/step - loss: 0.4071 - acc: 0.8113 - val_loss: 0.7303 - val_acc: 0.7419\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 196us/step - loss: 0.4067 - acc: 0.8062 - val_loss: 0.7501 - val_acc: 0.7386\n",
      "Epoch 179/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4153 - acc: 0.8014 - val_loss: 0.7442 - val_acc: 0.7408\n",
      "Epoch 180/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.4200 - acc: 0.8110 - val_loss: 0.7261 - val_acc: 0.7525\n",
      "Epoch 181/200\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.4008 - acc: 0.8113 - val_loss: 0.7311 - val_acc: 0.7503\n",
      "Epoch 182/200\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3995 - acc: 0.8141 - val_loss: 0.7566 - val_acc: 0.7480\n",
      "Epoch 183/200\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.4129 - acc: 0.8103 - val_loss: 0.7289 - val_acc: 0.7480\n",
      "Epoch 184/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4070 - acc: 0.8068 - val_loss: 0.7252 - val_acc: 0.7480\n",
      "Epoch 185/200\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.4203 - acc: 0.7989 - val_loss: 0.7192 - val_acc: 0.7503\n",
      "Epoch 186/200\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.4130 - acc: 0.8067 - val_loss: 0.7263 - val_acc: 0.7341\n",
      "Epoch 187/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.4125 - acc: 0.8088 - val_loss: 0.7382 - val_acc: 0.7391\n",
      "Epoch 188/200\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.4083 - acc: 0.8141 - val_loss: 0.7580 - val_acc: 0.7386\n",
      "Epoch 189/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4175 - acc: 0.8067 - val_loss: 0.7325 - val_acc: 0.7469\n",
      "Epoch 190/200\n",
      "3587/3587 [==============================] - 1s 196us/step - loss: 0.4128 - acc: 0.8022 - val_loss: 0.7443 - val_acc: 0.7492\n",
      "Epoch 191/200\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4097 - acc: 0.8058 - val_loss: 0.7261 - val_acc: 0.7436\n",
      "Epoch 192/200\n",
      "3587/3587 [==============================] - 1s 196us/step - loss: 0.4146 - acc: 0.8083 - val_loss: 0.7479 - val_acc: 0.7480\n",
      "Epoch 193/200\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4104 - acc: 0.8120 - val_loss: 0.7272 - val_acc: 0.7486\n",
      "Epoch 194/200\n",
      "3587/3587 [==============================] - 1s 277us/step - loss: 0.4083 - acc: 0.8074 - val_loss: 0.7479 - val_acc: 0.7453\n",
      "Epoch 195/200\n",
      "3587/3587 [==============================] - 1s 225us/step - loss: 0.4057 - acc: 0.8065 - val_loss: 0.7450 - val_acc: 0.7469\n",
      "Epoch 196/200\n",
      "3587/3587 [==============================] - 1s 204us/step - loss: 0.4122 - acc: 0.8150 - val_loss: 0.7553 - val_acc: 0.7436\n",
      "Epoch 197/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.4025 - acc: 0.8120 - val_loss: 0.7539 - val_acc: 0.7425\n",
      "Epoch 198/200\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.4073 - acc: 0.8085 - val_loss: 0.7397 - val_acc: 0.7436\n",
      "Epoch 199/200\n",
      "3587/3587 [==============================] - 1s 199us/step - loss: 0.4076 - acc: 0.8078 - val_loss: 0.7399 - val_acc: 0.7458\n",
      "Epoch 200/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.4019 - acc: 0.8092 - val_loss: 0.7546 - val_acc: 0.7480\n"
     ]
    }
   ],
   "source": [
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0],1 ,X_test.shape[1]))\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    checker = classifier.fit(X_train_lstm, Y_train, batch_size=32, epochs=200, validation_data = (X_test_lstm, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_label = classifier.predict(X_test_lstm)\n",
    "y_pred_test=np.argmax(Y_pred_test_label,axis =1)\n",
    "y_pred_test\n",
    "Y_pred_train_label = classifier.predict(X_train_lstm)\n",
    "y_pred_train = np.argmax(Y_pred_train_label,axis=1)\n",
    "Y_test_true = Y_test_org.astype(np.int)\n",
    "Y_train_true = Y_train_org.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.67      0.72       443\n",
      "          1       0.72      0.82      0.77       454\n",
      "\n",
      "avg / total       0.75      0.75      0.75       897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_true,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  \n",
      " [[1362   95]\n",
      " [ 437 1693]]\n",
      "\n",
      "Test:  \n",
      " [[297  80]\n",
      " [146 374]]\n"
     ]
    }
   ],
   "source": [
    "### for softmax function\n",
    "print(\"TRAIN:  \\n\",confusion_matrix(y_pred_train,Y_train_true))\n",
    "print(\"\\nTest:  \\n\",confusion_matrix(y_pred_test,Y_test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.76      0.84      1799\n",
      "          1       0.79      0.95      0.86      1788\n",
      "\n",
      "avg / total       0.87      0.85      0.85      3587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train_true,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
