{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       2242   2242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 =  df.query('label==0')\n",
    "df_class_1 =  df.query('label==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1],ignore_index=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4484, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  tweet\n",
       "label             \n",
       "0      2242   2242\n",
       "1      2242   2242"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_under['tweet']\n",
    "Y = df_under['label']\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ', lower=True, char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "# add padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @user lmfao pathetic #soit   #growup #funny #noonethere #iknowwhoitis ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98±ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f¤\\x97ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82â\\x80¦'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['tweet'], key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel(\"No. of components\")\n",
    "plt.ylabel(\"cummulative explained Variance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(LSTM(units=40, activation='relu',return_sequences= True, input_shape=(None, 35)))\n",
    "classifier.add(Dropout(rate=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(LSTM(units=20, return_sequences= True,activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(LSTM(units=20,activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(Dense(units = 2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='rmsprop',metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_e = OneHotEncoder()\n",
    "Y_train_org = Y_train\n",
    "Y_test_org = Y_test\n",
    "Y_train =np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "y_e.fit(Y_train)\n",
    "Y_train = y_e.transform(Y_train)\n",
    "Y_test = y_e.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 897 samples\n",
      "Epoch 1/200\n",
      "3587/3587 [==============================] - 5s 2ms/step - loss: 0.6924 - acc: 0.5548 - val_loss: 0.6912 - val_acc: 0.6026\n",
      "Epoch 2/200\n",
      "3587/3587 [==============================] - 1s 234us/step - loss: 0.6846 - acc: 0.6373 - val_loss: 0.6817 - val_acc: 0.6388\n",
      "Epoch 3/200\n",
      "3587/3587 [==============================] - 1s 224us/step - loss: 0.6699 - acc: 0.6583 - val_loss: 0.6820 - val_acc: 0.6661\n",
      "Epoch 4/200\n",
      "3587/3587 [==============================] - 1s 353us/step - loss: 0.6587 - acc: 0.6723 - val_loss: 0.6699 - val_acc: 0.6656\n",
      "Epoch 5/200\n",
      "3587/3587 [==============================] - 1s 286us/step - loss: 0.6442 - acc: 0.6744 - val_loss: 0.6672 - val_acc: 0.6734\n",
      "Epoch 6/200\n",
      "3587/3587 [==============================] - 1s 224us/step - loss: 0.6455 - acc: 0.6702 - val_loss: 0.6592 - val_acc: 0.6700\n",
      "Epoch 7/200\n",
      "3587/3587 [==============================] - 1s 227us/step - loss: 0.6329 - acc: 0.6761 - val_loss: 0.6589 - val_acc: 0.6616\n",
      "Epoch 8/200\n",
      "3587/3587 [==============================] - 1s 228us/step - loss: 0.6310 - acc: 0.6715 - val_loss: 0.6573 - val_acc: 0.6717\n",
      "Epoch 9/200\n",
      "3587/3587 [==============================] - 1s 227us/step - loss: 0.6301 - acc: 0.6815 - val_loss: 0.6494 - val_acc: 0.6689\n",
      "Epoch 10/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.6263 - acc: 0.6779 - val_loss: 0.6493 - val_acc: 0.6717\n",
      "Epoch 11/200\n",
      "3587/3587 [==============================] - 1s 234us/step - loss: 0.6227 - acc: 0.6798 - val_loss: 0.6531 - val_acc: 0.6745\n",
      "Epoch 12/200\n",
      "3587/3587 [==============================] - 1s 265us/step - loss: 0.6194 - acc: 0.6819 - val_loss: 0.6499 - val_acc: 0.6689\n",
      "Epoch 13/200\n",
      "3587/3587 [==============================] - 1s 221us/step - loss: 0.6213 - acc: 0.6893 - val_loss: 0.6441 - val_acc: 0.6689\n",
      "Epoch 14/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.6189 - acc: 0.6827 - val_loss: 0.6449 - val_acc: 0.6739\n",
      "Epoch 15/200\n",
      "3587/3587 [==============================] - 1s 228us/step - loss: 0.6174 - acc: 0.6847 - val_loss: 0.6478 - val_acc: 0.6722\n",
      "Epoch 16/200\n",
      "3587/3587 [==============================] - 1s 228us/step - loss: 0.6163 - acc: 0.6931 - val_loss: 0.6406 - val_acc: 0.6706\n",
      "Epoch 17/200\n",
      "3587/3587 [==============================] - 1s 234us/step - loss: 0.6158 - acc: 0.6864 - val_loss: 0.6377 - val_acc: 0.6745\n",
      "Epoch 18/200\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.6083 - acc: 0.6929 - val_loss: 0.6388 - val_acc: 0.6750\n",
      "Epoch 19/200\n",
      "3587/3587 [==============================] - 1s 208us/step - loss: 0.6046 - acc: 0.7025 - val_loss: 0.6416 - val_acc: 0.6728\n",
      "Epoch 20/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.6024 - acc: 0.6965 - val_loss: 0.6393 - val_acc: 0.6722\n",
      "Epoch 21/200\n",
      "3587/3587 [==============================] - 1s 234us/step - loss: 0.6025 - acc: 0.6961 - val_loss: 0.6415 - val_acc: 0.6722\n",
      "Epoch 22/200\n",
      "3587/3587 [==============================] - 1s 231us/step - loss: 0.6039 - acc: 0.6942 - val_loss: 0.6379 - val_acc: 0.6722\n",
      "Epoch 23/200\n",
      "3587/3587 [==============================] - 1s 233us/step - loss: 0.5966 - acc: 0.7034 - val_loss: 0.6348 - val_acc: 0.6750\n",
      "Epoch 24/200\n",
      "3587/3587 [==============================] - 1s 229us/step - loss: 0.5969 - acc: 0.7043 - val_loss: 0.6322 - val_acc: 0.6817\n",
      "Epoch 25/200\n",
      "3587/3587 [==============================] - 1s 213us/step - loss: 0.5971 - acc: 0.6984 - val_loss: 0.6343 - val_acc: 0.6839\n",
      "Epoch 26/200\n",
      "3587/3587 [==============================] - 1s 231us/step - loss: 0.5920 - acc: 0.7083 - val_loss: 0.6378 - val_acc: 0.6828\n",
      "Epoch 27/200\n",
      "3587/3587 [==============================] - 1s 233us/step - loss: 0.5941 - acc: 0.7109 - val_loss: 0.6297 - val_acc: 0.6901\n",
      "Epoch 28/200\n",
      "3587/3587 [==============================] - 1s 232us/step - loss: 0.5895 - acc: 0.7071 - val_loss: 0.6308 - val_acc: 0.6834\n",
      "Epoch 29/200\n",
      "3587/3587 [==============================] - 1s 219us/step - loss: 0.5919 - acc: 0.7057 - val_loss: 0.6332 - val_acc: 0.6851\n",
      "Epoch 30/200\n",
      "3587/3587 [==============================] - 1s 213us/step - loss: 0.5899 - acc: 0.7069 - val_loss: 0.6286 - val_acc: 0.6784\n",
      "Epoch 31/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.5871 - acc: 0.7105 - val_loss: 0.6286 - val_acc: 0.6878\n",
      "Epoch 32/200\n",
      "3587/3587 [==============================] - 1s 247us/step - loss: 0.5859 - acc: 0.7084 - val_loss: 0.6296 - val_acc: 0.6878\n",
      "Epoch 33/200\n",
      "3587/3587 [==============================] - 1s 251us/step - loss: 0.5791 - acc: 0.7149 - val_loss: 0.6299 - val_acc: 0.6918\n",
      "Epoch 34/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.5823 - acc: 0.7127 - val_loss: 0.6323 - val_acc: 0.6851\n",
      "Epoch 35/200\n",
      "3587/3587 [==============================] - 1s 217us/step - loss: 0.5836 - acc: 0.7140 - val_loss: 0.6369 - val_acc: 0.6834\n",
      "Epoch 36/200\n",
      "3587/3587 [==============================] - 1s 220us/step - loss: 0.5817 - acc: 0.7109 - val_loss: 0.6360 - val_acc: 0.6851\n",
      "Epoch 37/200\n",
      "3587/3587 [==============================] - 1s 209us/step - loss: 0.5778 - acc: 0.7187 - val_loss: 0.6343 - val_acc: 0.6895\n",
      "Epoch 38/200\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.5779 - acc: 0.7175 - val_loss: 0.6370 - val_acc: 0.6923\n",
      "Epoch 39/200\n",
      "3587/3587 [==============================] - 1s 208us/step - loss: 0.5713 - acc: 0.7243 - val_loss: 0.6369 - val_acc: 0.6845\n",
      "Epoch 40/200\n",
      "3587/3587 [==============================] - 1s 219us/step - loss: 0.5754 - acc: 0.7166 - val_loss: 0.6292 - val_acc: 0.6912\n",
      "Epoch 41/200\n",
      "3587/3587 [==============================] - 1s 216us/step - loss: 0.5718 - acc: 0.7207 - val_loss: 0.6295 - val_acc: 0.6901\n",
      "Epoch 42/200\n",
      "3587/3587 [==============================] - 1s 210us/step - loss: 0.5657 - acc: 0.7294 - val_loss: 0.6343 - val_acc: 0.6873\n",
      "Epoch 43/200\n",
      "3587/3587 [==============================] - 1s 208us/step - loss: 0.5656 - acc: 0.7247 - val_loss: 0.6372 - val_acc: 0.6856\n",
      "Epoch 44/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.5717 - acc: 0.7221 - val_loss: 0.6305 - val_acc: 0.6918\n",
      "Epoch 45/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5724 - acc: 0.7221 - val_loss: 0.6293 - val_acc: 0.6890\n",
      "Epoch 46/200\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.5713 - acc: 0.7176 - val_loss: 0.6364 - val_acc: 0.6901\n",
      "Epoch 47/200\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.5655 - acc: 0.7239 - val_loss: 0.6337 - val_acc: 0.6906\n",
      "Epoch 48/200\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5693 - acc: 0.7250 - val_loss: 0.6293 - val_acc: 0.6867\n",
      "Epoch 49/200\n",
      "3587/3587 [==============================] - 1s 209us/step - loss: 0.5609 - acc: 0.7255 - val_loss: 0.6250 - val_acc: 0.6929\n",
      "Epoch 50/200\n",
      "3587/3587 [==============================] - 1s 216us/step - loss: 0.5551 - acc: 0.7346 - val_loss: 0.6373 - val_acc: 0.6873\n",
      "Epoch 51/200\n",
      "3587/3587 [==============================] - 1s 218us/step - loss: 0.5544 - acc: 0.7294 - val_loss: 0.6280 - val_acc: 0.6912\n",
      "Epoch 52/200\n",
      "3587/3587 [==============================] - 1s 266us/step - loss: 0.5540 - acc: 0.7356 - val_loss: 0.6364 - val_acc: 0.6851\n",
      "Epoch 53/200\n",
      "3587/3587 [==============================] - 1s 252us/step - loss: 0.5535 - acc: 0.7299 - val_loss: 0.6284 - val_acc: 0.6851\n",
      "Epoch 54/200\n",
      "3587/3587 [==============================] - 1s 233us/step - loss: 0.5493 - acc: 0.7370 - val_loss: 0.6474 - val_acc: 0.6929\n",
      "Epoch 55/200\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.5494 - acc: 0.7399 - val_loss: 0.6480 - val_acc: 0.6945\n",
      "Epoch 56/200\n",
      "3587/3587 [==============================] - 1s 239us/step - loss: 0.5627 - acc: 0.7306 - val_loss: 0.6334 - val_acc: 0.6890\n",
      "Epoch 57/200\n",
      "3587/3587 [==============================] - 1s 262us/step - loss: 0.5529 - acc: 0.7303 - val_loss: 0.6329 - val_acc: 0.6895\n",
      "Epoch 58/200\n",
      "3587/3587 [==============================] - 1s 251us/step - loss: 0.5459 - acc: 0.7384 - val_loss: 0.6414 - val_acc: 0.6901\n",
      "Epoch 59/200\n",
      "3587/3587 [==============================] - 1s 221us/step - loss: 0.5484 - acc: 0.7363 - val_loss: 0.6433 - val_acc: 0.6901\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 238us/step - loss: 0.5534 - acc: 0.7340 - val_loss: 0.6321 - val_acc: 0.6912\n",
      "Epoch 61/200\n",
      "3587/3587 [==============================] - 1s 286us/step - loss: 0.5453 - acc: 0.7411 - val_loss: 0.6357 - val_acc: 0.6906\n",
      "Epoch 62/200\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.5443 - acc: 0.7400 - val_loss: 0.6320 - val_acc: 0.6945\n",
      "Epoch 63/200\n",
      "3587/3587 [==============================] - 1s 209us/step - loss: 0.5413 - acc: 0.7398 - val_loss: 0.6489 - val_acc: 0.6945\n",
      "Epoch 64/200\n",
      "3587/3587 [==============================] - 1s 212us/step - loss: 0.5346 - acc: 0.7445 - val_loss: 0.6460 - val_acc: 0.7018\n",
      "Epoch 65/200\n",
      "3587/3587 [==============================] - 1s 199us/step - loss: 0.5399 - acc: 0.7431 - val_loss: 0.6430 - val_acc: 0.6951\n",
      "Epoch 66/200\n",
      "3587/3587 [==============================] - 1s 235us/step - loss: 0.5419 - acc: 0.7400 - val_loss: 0.6442 - val_acc: 0.6979\n",
      "Epoch 67/200\n",
      "3587/3587 [==============================] - 1s 235us/step - loss: 0.5442 - acc: 0.7393 - val_loss: 0.6531 - val_acc: 0.6929\n",
      "Epoch 68/200\n",
      "3587/3587 [==============================] - 1s 229us/step - loss: 0.5493 - acc: 0.7368 - val_loss: 0.6400 - val_acc: 0.6951\n",
      "Epoch 69/200\n",
      "3587/3587 [==============================] - 1s 241us/step - loss: 0.5433 - acc: 0.7386 - val_loss: 0.6539 - val_acc: 0.6996\n",
      "Epoch 70/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.5346 - acc: 0.7432 - val_loss: 0.6398 - val_acc: 0.6996\n",
      "Epoch 71/200\n",
      "3587/3587 [==============================] - 1s 230us/step - loss: 0.5331 - acc: 0.7414 - val_loss: 0.6405 - val_acc: 0.6951\n",
      "Epoch 72/200\n",
      "3587/3587 [==============================] - 1s 253us/step - loss: 0.5297 - acc: 0.7501 - val_loss: 0.6623 - val_acc: 0.6968\n",
      "Epoch 73/200\n",
      "3587/3587 [==============================] - 1s 271us/step - loss: 0.5355 - acc: 0.7480 - val_loss: 0.6618 - val_acc: 0.7001\n",
      "Epoch 74/200\n",
      "3587/3587 [==============================] - 1s 261us/step - loss: 0.5337 - acc: 0.7452 - val_loss: 0.6529 - val_acc: 0.7018\n",
      "Epoch 75/200\n",
      "3587/3587 [==============================] - 1s 267us/step - loss: 0.5340 - acc: 0.7442 - val_loss: 0.6512 - val_acc: 0.6968\n",
      "Epoch 76/200\n",
      "3587/3587 [==============================] - 1s 259us/step - loss: 0.5294 - acc: 0.7503 - val_loss: 0.6531 - val_acc: 0.7012\n",
      "Epoch 77/200\n",
      "3587/3587 [==============================] - 1s 252us/step - loss: 0.5266 - acc: 0.7463 - val_loss: 0.6602 - val_acc: 0.7012\n",
      "Epoch 78/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.5251 - acc: 0.7530 - val_loss: 0.6501 - val_acc: 0.6996\n",
      "Epoch 79/200\n",
      "3587/3587 [==============================] - 1s 269us/step - loss: 0.5165 - acc: 0.7519 - val_loss: 0.6662 - val_acc: 0.6962\n",
      "Epoch 80/200\n",
      "3587/3587 [==============================] - 1s 257us/step - loss: 0.5208 - acc: 0.7543 - val_loss: 0.6527 - val_acc: 0.6940\n",
      "Epoch 81/200\n",
      "3587/3587 [==============================] - 1s 274us/step - loss: 0.5219 - acc: 0.7517 - val_loss: 0.6435 - val_acc: 0.7007\n",
      "Epoch 82/200\n",
      "3587/3587 [==============================] - 1s 267us/step - loss: 0.5248 - acc: 0.7490 - val_loss: 0.6472 - val_acc: 0.6973\n",
      "Epoch 83/200\n",
      "3587/3587 [==============================] - 1s 233us/step - loss: 0.5243 - acc: 0.7464 - val_loss: 0.6598 - val_acc: 0.6996\n",
      "Epoch 84/200\n",
      "3587/3587 [==============================] - 1s 305us/step - loss: 0.5259 - acc: 0.7490 - val_loss: 0.6601 - val_acc: 0.6962\n",
      "Epoch 85/200\n",
      "3587/3587 [==============================] - 1s 265us/step - loss: 0.5180 - acc: 0.7469 - val_loss: 0.6604 - val_acc: 0.6962\n",
      "Epoch 86/200\n",
      "3587/3587 [==============================] - 1s 237us/step - loss: 0.5122 - acc: 0.7583 - val_loss: 0.6669 - val_acc: 0.6951\n",
      "Epoch 87/200\n",
      "3587/3587 [==============================] - 1s 262us/step - loss: 0.5104 - acc: 0.7566 - val_loss: 0.6709 - val_acc: 0.6984\n",
      "Epoch 88/200\n",
      "3587/3587 [==============================] - 1s 251us/step - loss: 0.5174 - acc: 0.7559 - val_loss: 0.6828 - val_acc: 0.6878\n",
      "Epoch 89/200\n",
      "3587/3587 [==============================] - 1s 235us/step - loss: 0.5131 - acc: 0.7590 - val_loss: 0.6586 - val_acc: 0.7046\n",
      "Epoch 90/200\n",
      "3587/3587 [==============================] - 1s 226us/step - loss: 0.5099 - acc: 0.7580 - val_loss: 0.6653 - val_acc: 0.6984\n",
      "Epoch 91/200\n",
      "3587/3587 [==============================] - 1s 249us/step - loss: 0.5144 - acc: 0.7616 - val_loss: 0.6535 - val_acc: 0.6951\n",
      "Epoch 92/200\n",
      "3587/3587 [==============================] - 1s 254us/step - loss: 0.5146 - acc: 0.7563 - val_loss: 0.6529 - val_acc: 0.7007\n",
      "Epoch 93/200\n",
      "3587/3587 [==============================] - 1s 247us/step - loss: 0.5069 - acc: 0.7625 - val_loss: 0.6519 - val_acc: 0.7023\n",
      "Epoch 94/200\n",
      "3587/3587 [==============================] - 1s 247us/step - loss: 0.5176 - acc: 0.7582 - val_loss: 0.6435 - val_acc: 0.7040\n",
      "Epoch 95/200\n",
      "3587/3587 [==============================] - 1s 253us/step - loss: 0.5050 - acc: 0.7662 - val_loss: 0.6662 - val_acc: 0.7090\n",
      "Epoch 96/200\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.4967 - acc: 0.7724 - val_loss: 0.6754 - val_acc: 0.7040\n",
      "Epoch 97/200\n",
      "3587/3587 [==============================] - 1s 218us/step - loss: 0.5005 - acc: 0.7683 - val_loss: 0.6658 - val_acc: 0.7057\n",
      "Epoch 98/200\n",
      "3587/3587 [==============================] - 1s 227us/step - loss: 0.5095 - acc: 0.7615 - val_loss: 0.6419 - val_acc: 0.7068\n",
      "Epoch 99/200\n",
      "3587/3587 [==============================] - 1s 211us/step - loss: 0.5116 - acc: 0.7551 - val_loss: 0.6464 - val_acc: 0.7040\n",
      "Epoch 100/200\n",
      "3587/3587 [==============================] - 1s 259us/step - loss: 0.4998 - acc: 0.7678 - val_loss: 0.6633 - val_acc: 0.7023\n",
      "Epoch 101/200\n",
      "3587/3587 [==============================] - 1s 263us/step - loss: 0.5043 - acc: 0.7591 - val_loss: 0.6629 - val_acc: 0.7046\n",
      "Epoch 102/200\n",
      "3587/3587 [==============================] - 1s 238us/step - loss: 0.5058 - acc: 0.7595 - val_loss: 0.6604 - val_acc: 0.7057\n",
      "Epoch 103/200\n",
      "3587/3587 [==============================] - 1s 292us/step - loss: 0.5024 - acc: 0.7637 - val_loss: 0.6590 - val_acc: 0.7051\n",
      "Epoch 104/200\n",
      "3587/3587 [==============================] - 1s 299us/step - loss: 0.4975 - acc: 0.7710 - val_loss: 0.6531 - val_acc: 0.7062\n",
      "Epoch 105/200\n",
      "3587/3587 [==============================] - 1s 283us/step - loss: 0.4961 - acc: 0.7669 - val_loss: 0.6428 - val_acc: 0.7101\n",
      "Epoch 106/200\n",
      "3587/3587 [==============================] - 1s 288us/step - loss: 0.4956 - acc: 0.7647 - val_loss: 0.6707 - val_acc: 0.6951\n"
     ]
    }
   ],
   "source": [
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0],1 ,X_test.shape[1]))\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    checker = classifier.fit(X_train_lstm, Y_train, batch_size=32, epochs=200, validation_data = (X_test_lstm, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_label = classifier.predict(X_test_lstm)\n",
    "y_pred_test=np.argmax(Y_pred_test_label,axis =1)\n",
    "y_pred_test\n",
    "Y_pred_train_label = classifier.predict(X_train_lstm)\n",
    "y_pred_train = np.argmax(Y_pred_train_label,axis=1)\n",
    "Y_test_true = Y_test_org.astype(np.int)\n",
    "Y_train_true = Y_train_org.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_true,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for softmax function\n",
    "print(\"TRAIN:  \\n\",confusion_matrix(y_pred_train,Y_train_true))\n",
    "print(\"\\nTest:  \\n\",confusion_matrix(y_pred_test,Y_test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train_true,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
